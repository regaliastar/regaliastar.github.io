<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>从零开始量子计算（1）：体系结构</title>
      <link href="2020/10/21/qc-1/"/>
      <url>2020/10/21/qc-1/</url>
      
        <content type="html"><![CDATA[<h2 id="0x00-前言"><a href="#0x00-前言" class="headerlink" title="0x00 前言"></a>0x00 前言</h2><p>作为一个工程师，我习惯于对任何看起来神秘的事物刨根问底，量子计算同样如此。看到一辆玩具小车在横冲直撞，我会思考这是因为电池驱动的马达带动轴承做旋转运动；看到日升日落，我会思考这是由于万有引力的束缚，抑或是广义相对论的时空约束。<br>万物均有体系结构，就算是看起来最反常识的量子力学，也接受薛定谔方程的描述。因此，我把<code>体系结构</code>作为本系列的第一篇文章，看懂了体系结构才能让人对整个系统有一个印象。<br>或许是我担任”计算机组成与体系结构”这门课程助教的原因:)，体系结构这个话题可以聊的就太多了。然而我毕竟不是搞的芯片，因此本文从工程的角度出发，对比经典与量子两种架构，对其进行一个全面的阐述。  </p><h2 id="0x01-经典架构"><a href="#0x01-经典架构" class="headerlink" title="0x01 经典架构"></a>0x01 经典架构</h2><p>首先讨论经典计算机的架构，先从最基本的单元说起。<br>经典计算机基本单元是比特0-1，用高电平和低电平来表示。比特的基本处理单元是逻辑门，而逻辑门使用晶体管实现。同时使用晶体管可以来构建存储单元SRAM、DRAM，前者是register、cache的主要成分，后者则是memory的主要成分。同样的，像是CPU中的处理单元加法器、算术逻辑单元等等，这些都可以通过晶体管构成。存储单元和处理单元是可以分开的，所以我们有非常出名的冯诺依曼体系结构，它告诉人们一台计算机可以用什么样的方式搭建出来。  </p><p><img src="/img/qc-1-1.png" alt="Fig. 1: MIPS microarchitecture"></p><p>上图是一个极度简化的CPU的组成，它包含几个部分，总的概括便是存储器和算术逻辑单元，为了让存储和运算单元组合到一起工作，于是有一个控制器。这些所有单元都是由晶体管构成，所以我们说，数据的存储、处理、控制都是同质的（homogeneous），因此我们可以把它集成到同一块芯片上来。<br>有了这样一个架构，我们就可以在上面运行软件了。比如有一个AI应用，它是用编程语言python来实现的，经过编译器进行编译，生成了二进制文件。这些二进制的指令，便放在处理器上面执行。于是经典计算机自顶向下的流程便结束了。  </p><p><img src="/img/qc-1-2.png">  </p><h2 id="0x02-量子架构"><a href="#0x02-量子架构" class="headerlink" title="0x02 量子架构"></a>0x02 量子架构</h2><p>有了经典架构做铺垫，再看量子环境会有什么不同。首先从最基本的单元说起。量子计算机最基本的单元是量子比特（qubit），而量子比特<br>$$\mathinner{|\phi\rangle} = \alpha\mathinner{|0\rangle} + \beta\mathinner{|1\rangle} s.t. |\alpha|^2 + |\beta|^2 = 1$$<br>表示该比特有|α|^2的概率为0，否则为1。该量子比特处于0和1的叠加态之中。同理，若有n个qubit则系统同时有2^n个状态的叠加。<br>量子计算和经典计算不同的一点在于，量子比特既是数据存储的单元，又是数据处理的单元，因此运算过程就发生在量子比特身上。经典计算机使用逻辑门处理比特，而量子计算机使用量子门来处理。量子门处理的过程是对所有比特进行处理，同时有着巨大的状态空间以及巨大的并行性，因此量子算法效率往往会有指数级别的提升。在简单的介绍之后，下面从工程的角度来看一些实物，一个量子芯片到底该长啥样。  </p><p><img src="/img/qc-1-3.png">  </p><p>上图量子芯片来自荷兰代尔夫特理工大学实验室，它在20mK温度下工作，只有两个量子比特[28]（芯片中央两个黑色圆点）。现探索该量子比特的结构。<br>图1.11(a)则为上图量子芯片中的量子比特放大图，可以看到上极板有3个接口，下极板也有3个接口连接出去，两个极板中间有一层介质，它们共同构成了电容。图1.11(b)是该结构的电路图，图中线条标注了它们之间的对应关系。  </p><p><img src="/img/qc-1-4.png" alt="图片">    </p><p>图中黑色线条相连的部分是电容，红色线条相连的部分是约瑟夫森结（Josephson junction）。这两个约瑟夫森结等效于一个电感，于是这个电路中有了电容、电感，就构成了一个LC振荡电路。那么能量就在电容与电感之间来回震荡。如果用量子电动力学去探索它的基态，可以看到它是一个等分的能级的结构，于是我们可以得到这样一个能量间隔不均匀的能级图：  </p><p><img src="/img/qc-1-5.png">    </p><p>取最低能级为0，取第一激发态为1来作为量子态，这样就构成了一个量子比特。注意在这里，我们观测的是整个约瑟夫森结的状态，也就是说观测的量子状态是宏观的，这就相当于用宏观的表现来观测到了微观的量子状态，所以我们才能操作量子比特。<br>有了量子比特后，该怎么对量子比特进行操纵呢，这是通过良好定义的波形来实现的。在图1.10中，可以看到该量子芯片周围有6个接口，这些接口通过导线连接到外部，因此能够通过这些接口把波形传到量子比特上面去。比如说单比特门就用20ns的脉冲，通过接口打在量子比特上面去。<br>现在回到上面说的问题，在经典计算机中，存储单元和处理单元是分离的。而在量子计算机中，量子比特既是数据存储的地方，又是数据处理的地方，控制媒介则是模拟波形（模拟信号）。经典电路控制媒介则是数字信号。在经典的架构中，有了CPU便可以直接安装软件运行，而在量子计算机中，由于它们是异构的（同时存在模拟/数字信号），则需要一个专门的控制器来进行沟通转换。就是说在软件和量子比特之间一定要引入一个控制器。  </p><p><img src="/img/qc-1-6.png">    </p><p>上图中，AWG（Arbitrary waveform generator）是任意波形发生器的缩写，用它来发射定义好的模拟波形来操作量子比特。Data Collection Card（数据采集卡）用来采集测量量子比特后返回的结果，这个测量结果也是模拟信号，所以要对模拟信号进行识别从而判断结果是0还是1。整个流程便是PC机软件控制发出数字波形，然后控制器中的AWGs发出定义好的模拟波形打在量子比特上，最后测量结果返回给数字采集卡，数字采集卡判断结果后返回给PC主机。这是过去主流的控制量子比特的方法，也是目前少数实验室采用的方法，但是它是不可扩展的，因此后面会提到全栈量子计算机的架构。<br>现在可以比较经典计算和量子计算的不同了：  </p><ol><li>从数据流过程上。经典计算是把数据流拿出来运动，经过一个个函数/运算模块中处理，最后得到结果。所以是数据在动，操作不动。而量子计算中，所有数据保存在量子比特上面，我们把操作一个个的打上去，所以是数据不动，操作在动。这种不同也决定了量子计算机的体系结构和经典是不同的。  </li><li>从编程语言上。经典计算发展到现在，有无数编程语言能够满足经典计算的使用。为了描述与操作量子比特，现在也有很多量子高级语言（如Qiskit），然而这些语言经典算法中的高级特性，如递归等操作并没有很好的实现。在使用量子高级语言的时候，更多的是考虑如何实现电路图，这对于量子算法的产生是个很不利的因素。<br>在图1.13控制方法中，控制流程是不可扩展的，因此现在主流的组成如下图所示  </li></ol><p><img src="/img/qc-1-7.png">  </p><p>最上层是一些量子算法，如shor算法等等；中间一层是编程语言和编译器，如Qiskit、Q#、QPanda等等；再下面是要转化成的指令集，如eQASM、OpenQASM；最下层便是量子芯片，可能是超导芯片、离子阱等等。<br>接下来看看IBM对它的物理实现：  </p><p><img src="/img/qc-1-8.png">  </p><p>上图(a)就是IBM展示的量子计算机，(b)是封装起来的样子，其内部是一个大号的“冰箱”，芯片要求在20mK的温度下工作。    </p><h2 id="0x03-现在-amp-未来"><a href="#0x03-现在-amp-未来" class="headerlink" title="0x03 现在&amp;未来"></a>0x03 现在&amp;未来</h2><p>上面说了那么多过去的知识，接下来看看现在此刻的芯片所处的时代~<br>学术界预计在未来几年内，我们将进入有噪声中间量子(Noisy Intermediate-Scale Quantum,NISQ)时代，届时具有数十到数百个量子位元的QC器件将面世。<br>虽然量子位的数量不足以构成量子纠错(QEC)，但它仍然被期望使用超出可用的经典计算机的能力，来解决现实世界的问题。<br>在NISQ时代，由于技术的限制，量子软件和硬件之间存在差距。当前最流行的电路模型设计一个量子程序时，总是假设量子位和量子操作是完美的，你可以应用任何量子物理操作。但在NISQ硬件上，量子位的相干时间有限，量子运算也不完美。下图是 IBM Q20 芯片，可以看到其参数如图  </p><p><img src="/img/qc-1-9.png" alt="Fig. 2:  IBM Q20 Tokyo Information">  </p><p>上图显示了有关IBMQ 20芯片的信息，量子比特的平均寿命仅仅约为50µs，同时量子门之间的操作也有错误率，这意味着该芯片将无法运行大规模的程序。量子比特被放置在一个平面几何体上，由于芯片上的放置和路由限制，耦合器只能将一个量子比特连接到相邻的量子比特上。<br>有学者估计，要使量子计算机达到通用计算机的程度，至少需要数十万个量子比特，而当前的进展仅仅是几十个比特。或许将量子计算机作为专用计算才是未来的方向，毕竟从理论到实践的路还很漫长…<br>事实上，如今的量子计算机是作为云的形式提供服务的，因为目前最流行的超导体系结构无法在室温下工作，所以只能通过提供API的方式调用。这是不是很像云计算？这也是实验室之外唯一能够使用量子芯片的方法了，目前国外有IBM提供的免费量子芯片可供使用（虽然才5比特…），并且需要排队才能申请到使用权限。    </p><p>PS：前两天习大大提出要发展量子科技，难道这个冷门中的冷门方向要出头了吗？！惊了！</p><blockquote><p>Reference<br>[1] John Preskill. Quantum computing in the nisq era and beyond. arXiv preprint arXiv:1801.00862, 2018.<br>[2] Sergio Boixo, Sergei V Isakov, Vadim N Smelyanskiy, Ryan Babbush, Nan Ding, Zhang Jiang, Michael J Bremner, John M Martinis, and Hartmut Neven. Characterizing quantum supremacy in near-term devices. Nature Physics, 14(6):595, 2018.<br>[3] IBM. IBM Q Experience Device. <a href="https://quantumexperience.ng.bluemix/">https://quantumexperience.ng.bluemix</a>. net/qx/devices, 2018.<br>[4] Li G, Ding Y, Xie Y. Tackling the qubit mapping problem for NISQ-era quantum devices[C]//Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems. 2019: 1001-1014.  </p></blockquote>]]></content>
      
      
      <categories>
          
          <category> 量子计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 从零开始量子计算 </tag>
            
            <tag> 科普 </tag>
            
            <tag> 体系结构 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
